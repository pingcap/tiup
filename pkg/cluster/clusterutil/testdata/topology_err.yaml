# # Global variables are applied to all deployments and as the default value of
# # them if the specific deployment value missing.

global:
  user: "tidb"
  ssh_port: 22
  deploy_dir: "/tidb/deploy"
  data_dir: "/tidb/data"

# # Monitored variables are used to all the machine
monitored:
  node_exporter_port: 9100
  blackbox_exporter_port: 9115
  # deploy_dir: "/tidb/deploy/monitored-9100"
  # data_dir: "/tidb/data/monitored-9100"
  # log_dir: "/tidb/deploy/monitored-9100/log"

# # Server configs are used to specify the runtime configuration of TiDB components
# # All configuration items can be found in TiDB docs:
# # - TiDB: https://pingcap.com/docs/stable/reference/configuration/tidb-server/configuration-file/
# # - TiKV: https://pingcap.com/docs/stable/reference/configuration/tikv-server/configuration-file/
# # - PD: https://pingcap.com/docs/stable/reference/configuration/pd-server/configuration-file/
# # All configuration items use points to represent the hierarchy, e.g:
# #   readpool.storage.use-unified-pool
# #           ^       ^
# # You can overwrite this configuration via instance-level `config` field

server_configs:
  tidb:
    log.slow-threshold: 300
    binlog.enable: false
    binlog.ignore-error: false
  tikv:
    # server.grpc-concurrency: 4
    # raftstore.apply-pool-size: 2
    # raftstore.store-pool-size: 2
    # rocksdb.max-sub-compactions: 1
    # storage.block-cache.capacity: "16GB"
    # readpool.unified.max-thread-count: 12
    readpool.storage.use-unified-pool: true
    readpool.coprocessor.use-unified-pool: true
  pd:
    schedule.leader-schedule-limit: 4
    schedule.region-schedule-limit: 2048
    schedule.replica-schedule-limit: 64
  # tiflash:
  #   logger.level: "info"
  # tiflash-learner:
  #   log-level: "info"
  # pump:
  #   gc: 7

pd_servers:
  - host: 10.160.22.100
    # ssh_port: 22
    # name: "pd-1"
    # client_port: 2379
    # peer_port: 2380
    # deploy_dir: "/tidb/deploy/pd-2379"
    # data_dir: "/tidb/data/pd-2379"
    # log_dir: "/tidb/deploy/pd-2379/log"
    # numa_node: "0,1"
    # # Config is used to overwrite the `server_configs.pd` values
    # config:
    #   schedule.max-merge-region-size: 20
    #   schedule.max-merge-region-keys: 200000
  - host: 10.160.22.101
  - host: 10.160.22.102

tidb_servers:
  - host: 10.160.22.107
    # ssh_port: 22
    # port: 4000
    # status_port: 10080
    # deploy_dir: "/tidb/deploy/tidb-4000"
    # log_dir: "/tidb/deploy/tidb-4000/log"
    # numa_node: "0,1"
    # # Config is used to overwrite the `server_configs.tidb` values
    # config:
    #   log.slow-query-file: tidb-slow-overwrited.log
  - host: 10.160.22.108
#  - host: 10.0.1.9

tikv_servers:
  - host: 10.160.22.103
    # ssh_port: 22
    # port: 20160
    # status_port: 20180
    # deploy_dir: "/tidb/deploy/tikv-20160"
    # data_dir: "/tidb/data/tikv-20160"
    # log_dir: "/tidb/deploy/tikv-20160/log"
    # numa_node: "0,1"
    # # Config is used to overwrite the `server_configs.tikv` values
    # config:
    #   server.grpc-concurrency: 4
    #   server.labels: { zone: "zone1", dc: "dc1", host: "host1" }
  - host: 10.160.22.104
  - host: 10.160.22.105

# tiflash_servers:
#   - host: 10.0.1.10
#     ssh_port: 22
#     tcp_port: 9000
#     http_port: 8123
#     flash_service_port: 3930
#     flash_proxy_port: 20170
#     flash_proxy_status_port: 20292
#     metrics_port: 8234
#     deploy_dir: /tidb/deploy/tiflash-9000
#     data_dir: /tidb/data/tiflash-9000
#     log_dir: /tidb/deploy/tiflash-9000/log
#     numa_node: "0,1"
#     # Config is used to overwrite the `server_configs.tiflash` values
#     config:
#       logger.level: "info"
#     # The following config is used to overwrite the `server_configs.tiflash-learner` values
#     learner_config:
#       log-level: "info"
#   - host: 10.0.1.15
#   - host: 10.0.1.16

# pump_servers:
#   - host: 10.0.1.17
#     ssh_port: 22
#     port: 8250
#     deploy_dir: "/tidb/deploy/pump-8249"
#     data_dir: "/tidb/data/pump-8249"
#     log_dir: "/tidb/deploy/pump-8249/log"
#     numa_node: "0,1"
#     # Config is used to overwrite the `server_configs.drainer` values
#     config:
#       gc: 7
#   - host: 10.0.1.18
#   - host: 10.0.1.19

# drainer_servers:
#   - host: 10.0.1.17
#     port: 8249
#     data_dir: "/tidb/data/drainer-8249"
#     # if drainer doesn't have checkpoint, use initial commitTS to initial checkpoint
#     # will get a latest timestamp from pd if setting to be -1 (default -1)
#     commit_ts: -1
#     deploy_dir: "/tidb/deploy/drainer-8249"
#     log_dir: "/tidb/deploy/drainer-8249/log"
#     numa_node: "0,1"
#     # Config is used to overwrite the `server_configs.drainer` values
#     config:
#       syncer.db-type: "mysql"
#       syncer.to.host: "127.0.0.1"
#       syncer.to.user: "root"
#       syncer.to.password: ""
#       syncer.to.port: 3306
#   - host: 10.0.1.19

monitoring_servers:
  - host: 10.160.22.106
    # ssh_port: 22
    # port: 9090
    # deploy_dir: "/tidb/deploy/prometheus-8249"
    # data_dir: "/tidb/data/prometheus-8249"
    # log_dir: "/tidb/deploy/prometheus-8249/log"

grafana_servers:
  - host: 10.160.22.106
    # port: 3000
    # deploy_dir: /tidb/deploy/grafana-3000

alertmanager_servers:
  - host: 10.160.22.106
    # ssh_port: 22
    # web_port: 9093
    # cluster_port: 9094
    # deploy_dir: "/tidb/deploy/alertmanager-9093"
    # data_dir: "/tidb/data/alertmanager-9093"
    # log_dir: "/tidb/deploy/alertmanager-9093/log"
